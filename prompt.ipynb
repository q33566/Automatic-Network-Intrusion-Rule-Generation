{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the pickle file and find the top five occurance rate payloads in the file\n",
    "Return the payloads as 'text'讀取出text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pop_report_with_tknscore_new.pkl\", \"rb\") as f:\n",
    "    pop_df = pickle.load(f)\n",
    "\n",
    "with open(\"imap_report_with_tknscore_new.pkl\", \"rb\") as f:\n",
    "    imap_df = pickle.load(f)\n",
    "\n",
    "with open(\"smtp_report_with_tknscore_new.pkl\", \"rb\") as f:\n",
    "    smtp_df = pickle.load(f)\n",
    "\n",
    "with open(\"sip_report_with_tknscore_new.pkl\", \"rb\") as f:\n",
    "    sip_df = pickle.load(f)\n",
    "\n",
    "label_df = pd.read_csv(\"sid_table(packet).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 流程\n",
    "### 獲取目標資料\n",
    "- 獲取特定資料集的所有SID(unique)\n",
    "- 獲取各個SID所對應到的text\n",
    "- 過濾出sizt(text)>5的SID\n",
    "- 對這些SID用LLM自動生成regex(生成Regex流程)\n",
    "### 生成Regex\n",
    "- 對每一個SID給LLM幾個regex例子\n",
    "- 要求LLM生成三個不一樣但是可以過濾text的regex\n",
    "### 測試Regex\n",
    "- 拿答案給的regex和我們生成的regex測試能否的到相同結果(2/3過算對)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#獲取特定資料集的所有SID\n",
    "def get_unique_sids_list(df):\n",
    "    unique_sids = df[df['text'].notnull()]['sid'].unique()\n",
    "    return unique_sids\n",
    "sidList = get_unique_sids_list(pop_df)\n",
    "print(sidList)\n",
    "print(len(sidList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#獲取各個SID所對應到的text\n",
    "def map_sid_to_unique_texts(df):\n",
    "    sid_to_texts = {}\n",
    "    for _, row in df.iterrows():\n",
    "        sid = row['sid']\n",
    "        text = row['text']\n",
    "        if pd.notnull(text):  # Ensure text is not NaN\n",
    "            if sid in sid_to_texts:\n",
    "                sid_to_texts[sid].add(text)\n",
    "            else:\n",
    "                sid_to_texts[sid] = {text}\n",
    "    return sid_to_texts\n",
    "sid_to_unique_texts = map_sid_to_unique_texts(pop_df)\n",
    "print(sid_to_unique_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#過濾掉text長度小於5的sid\n",
    "def filter_sids_by_text_length(sit_to_text_dict):\n",
    "    filtered_sids = set()\n",
    "    for key, value in sit_to_text_dict.items():\n",
    "        if len(value) > 5:  # Convert to string to avoid errors with non-string types\n",
    "            filtered_sids.add(key)\n",
    "    return filtered_sids\n",
    "\n",
    "# Assuming pop_df is your DataFrame\n",
    "filtered_sids = filter_sids_by_text_length(sid_to_unique_texts)\n",
    "print(filtered_sids)\n",
    "print(len(filtered_sids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPT API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "CHAT_GPT_API_KEY = os.getenv('C_API_KEY')\n",
    "client = OpenAI(\n",
    "    api_key=CHAT_GPT_API_KEY\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "system_prompt = \"You are a cat. Your name is Neko.\"\n",
    "user_prompt = \"What is your name?\"\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "model=genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  system_instruction=system_prompt)\n",
    "\n",
    "response = model.generate_content(user_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Generated Regex\n",
    "Randonly take 20 positive and 20 negateve data as input to generated regex and answer regex, comparing there result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive test\n",
      "correct: 25, total: 45\n",
      "errorList: ['USER administrator\\r\\n', 'USER root\\r\\n', 'USER test\\r\\n', 'USER data\\r\\n', 'USER pwrchute\\r\\n', 'USER informix\\r\\n', 'USER oracle\\r\\n', 'USER access\\r\\n', 'USER admin\\r\\n', 'USER account\\r\\n', 'USER server\\r\\n', 'USER webmaster\\r\\n', 'USER user\\r\\n', 'USER backup\\r\\n', 'USER www\\r\\n', 'USER lizdy\\r\\n', 'USER sybase\\r\\n', 'USER web\\r\\n', 'USER oracle8\\r\\n', 'USER world@gmail.com']\n",
      "negative test\n",
      "correct: 100, total: 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import csv\n",
    "import random\n",
    "\n",
    "#隨機選擇除了給定的SID以外的100個text\n",
    "def select_random_texts(sid_to_unique_texts, given_sid, num_texts=100):\n",
    "    # Filter out the given SID\n",
    "    filtered_texts = [texts for sid, texts in sid_to_unique_texts.items() if sid != given_sid]\n",
    "    \n",
    "    # Flatten the list of lists to a single list of texts\n",
    "    all_texts = [text for sublist in filtered_texts for text in sublist]\n",
    "    \n",
    "    # Randomly select 100 texts, or all texts if there are fewer than 100\n",
    "    selected_texts = random.sample(all_texts, min(len(all_texts), num_texts))\n",
    "    \n",
    "    return selected_texts\n",
    "\n",
    "def get_pcre_by_sid(sid):\n",
    "    with open('sid_table(packet).csv', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            if row['SID'] == str(sid):\n",
    "                # Remove leading and trailing slashes from the pcre value\n",
    "                return row['pcre'].strip('/')\n",
    "    return None\n",
    "\n",
    "def match_patterns(targetText, threeAnsPattern,ansPattern):\n",
    "    match1 = bool(re.search(threeAnsPattern[0], targetText))\n",
    "    match2 = bool(re.search(threeAnsPattern[1], targetText))\n",
    "    match3 = bool(re.search(threeAnsPattern[2], targetText))\n",
    "    match4 = bool(re.search(threeAnsPattern[3], targetText))\n",
    "    match5 = bool(re.search(threeAnsPattern[4], targetText))\n",
    "    match6 = bool(re.search(threeAnsPattern[5], targetText))\n",
    "    match7 = bool(re.search(threeAnsPattern[6], targetText))\n",
    "    match8 = bool(re.search(threeAnsPattern[7], targetText))\n",
    "    match9 = bool(re.search(threeAnsPattern[8], targetText))\n",
    "    ourResult = sum([match1, match2, match3, match4, match5, match6, match7, match8, match9]) >= 7\n",
    "    ansMatch = bool(re.search(ansPattern, targetText))\n",
    "    return ourResult == ansMatch\n",
    "def positive_evaluation(threeAnsPattern,sid):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    errorList = []\n",
    "    ansPattern = get_pcre_by_sid(str(sid))\n",
    "    sid_to_unique_texts = map_sid_to_unique_texts(pop_df)\n",
    "    texts = sid_to_unique_texts[sid]\n",
    "    for text in texts:\n",
    "        total = total + 1\n",
    "        correct = correct + match_patterns(text, threeAnsPattern, ansPattern)\n",
    "        if not match_patterns(text, threeAnsPattern, ansPattern):\n",
    "            errorList.append(text)\n",
    "\n",
    "    print(\"positive test\")\n",
    "    print(f\"correct: {correct}, total: {total}\")\n",
    "    print(f\"errorList: {errorList}\")\n",
    "    return correct, total\n",
    "\n",
    "def negative_evaluation(GeneratedPatternList,sid):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    errorList = []\n",
    "    ansPattern = get_pcre_by_sid(str(sid))\n",
    "    texts = select_random_texts(sid_to_unique_texts, sid)\n",
    "    for text in texts:\n",
    "        total = total + 1\n",
    "        correct = correct + match_patterns(text, GeneratedPatternList, ansPattern)\n",
    "        if  not match_patterns(text, GeneratedPatternList, ansPattern):\n",
    "            errorList.append(text)\n",
    "    print(\"negative test\")\n",
    "    print(f\"correct: {correct}, total: {total}\")\n",
    "    for error_text in errorList:\n",
    "        print(error_text)\n",
    "    #print(f\"errorList: {errorList}\")\n",
    "GeneratedPatternList = [\n",
    "    r\"^USER [^\\s@]+(?:@[^\\s@]+\\.[^\\s@]+)?\\r\\n$\",\n",
    "    r\"^USER (anonymous|[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\\r\\n$\",\n",
    "    r\"^USER (spam\\.(blocked|passed)@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}|anonymous)\\r\\n$\",\n",
    "    r\"^USER (\\S+@\\S+\\.\\S+|\\S+)\\r\\n$\",\n",
    "    r\"^USER \\S+@\\S+\\.\\S+\\r\\n$|^USER \\S+\\r\\n$\",\n",
    "    r\"^USER (\\w+@\\w+\\.\\w+|\\w+)\\r\\n$\",\n",
    "    r\"^USER\\s\\S+(\\.\\S+)?\\r\\n$\",\n",
    "    r\"^USER\\s[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,4}\\r\\n|^USER\\sanonymous\\r\\n$\",\n",
    "    r\"^USER\\s([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,4}|anonymous)\\r\\n$\"\n",
    "]\n",
    "\n",
    "sid = '1648627'\n",
    "positive_evaluation(GeneratedPatternList, sid)\n",
    "negative_evaluation(GeneratedPatternList, sid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_csv_columns():\n",
    "    with open('sid_table(packet).csv', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        # Print all column names\n",
    "        print(reader.fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print filtered_sids and corresponding text\n",
    "for sid in filtered_sids:\n",
    "    print(f\"sid: {sid}, text: {sid_to_unique_texts[sid]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "protocols = [\n",
    "    {'name': 'pop_df', 'data': pop_df},\n",
    "    {'name': 'imap_df', 'data': imap_df},\n",
    "    {'name': 'smtp_df', 'data': smtp_df},\n",
    "    {'name': 'sip_df', 'data': sip_df}\n",
    "]\n",
    "\n",
    "with open('target.txt', 'w') as file:\n",
    "    pass\n",
    "\n",
    "with open('target.txt', 'a') as file:\n",
    "    for protocol in protocols:\n",
    "        protocol_name = protocol['name']\n",
    "        protocol_data = protocol['data']\n",
    "        \n",
    "        sid_to_unique_texts = map_sid_to_unique_texts(protocol_data)\n",
    "        filtered_sids = filter_sids_by_text_length(sid_to_unique_texts)\n",
    "        \n",
    "        file.write(f\"Protocol: {protocol_name}\\n\")\n",
    "        \n",
    "        for sid in filtered_sids:\n",
    "            for i in range (3):\n",
    "                texts = list(sid_to_unique_texts[sid])\n",
    "                random.shuffle(texts)\n",
    "                selected_texts = texts[:5]\n",
    "                file.write(f\"sid: {sid}, text: {selected_texts}\\n\")\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_texts.txt', 'a') as file:\n",
    "    for protocol in protocols:\n",
    "        protocol_name = protocol['name']\n",
    "        protocol_data = protocol['data']\n",
    "        \n",
    "        sid_to_unique_texts = map_sid_to_unique_texts(protocol_data)\n",
    "        filtered_sids = filter_sids_by_text_length(sid_to_unique_texts)\n",
    "        \n",
    "        file.write(f\"Protocol: {protocol_name}\\n\")\n",
    "        \n",
    "        for sid in filtered_sids:\n",
    "            file.write(f\"sid: {sid}, text: {sid_to_unique_texts[sid]}\\n\")\n",
    "\n",
    "        file.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
