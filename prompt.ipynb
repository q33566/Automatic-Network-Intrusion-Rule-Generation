{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import random\n",
    "import regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#獲取特定資料集的所有SID\n",
    "def get_unique_sids_list(df):\n",
    "    unique_sids = df[df['text'].notnull()]['sid'].unique()\n",
    "    return unique_sids\n",
    "sidList = get_unique_sids_list(pop_df)\n",
    "print(sidList)\n",
    "#print(len(sidList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "def readPkl(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def readCsv(file):\n",
    "    data = pd.read_csv(file)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FileProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "def get_unique_sids_list(df):\n",
    "    unique_sids = df[df['text'].notnull()]['sid'].unique()\n",
    "    return unique_sids\n",
    "\n",
    "def map_sid_to_unique_texts(df):\n",
    "    sid_to_texts = {}\n",
    "    for _, row in df.iterrows():\n",
    "        sid = row['sid']\n",
    "        text = row['text']\n",
    "        if pd.notnull(text):  # 確保 text 不是 NaN\n",
    "            if sid in sid_to_texts:\n",
    "                sid_to_texts[sid].add(text)\n",
    "            else:\n",
    "                sid_to_texts[sid] = {text}\n",
    "    return sid_to_texts\n",
    "\n",
    "\n",
    "def merge_dataframes_to_dict(dfs):\n",
    "    \"\"\"\n",
    "    Merge multiple dataframes into a dictionary where each sid maps to a list of unique texts.\n",
    "\n",
    "    :param dfs: List of pandas DataFrames, each with columns 'sid' and 'text'\n",
    "    :return: Dictionary with sid as keys and list of unique texts as values\n",
    "    \"\"\"\n",
    "    merged_dict = {}\n",
    "\n",
    "    for df in dfs:\n",
    "        for _, row in df.iterrows():\n",
    "            sid = row['sid']\n",
    "            text = row['text']\n",
    "            if sid not in merged_dict:\n",
    "                merged_dict[sid] = set()  # Use a set to avoid duplicates\n",
    "            merged_dict[sid].add(text)\n",
    "\n",
    "    # Convert sets to lists\n",
    "    merged_dict = {sid: list(texts) for sid, texts in merged_dict.items()}\n",
    "    \n",
    "    return merged_dict\n",
    "\n",
    "def filter_sids_by_text_length(sid_to_texts_dict):\n",
    "    filtered_sid_to_texts_dict = set()\n",
    "    for key, value in sid_to_texts_dict.items():\n",
    "        if len(value) > 5:  # 確保字串長度超過 5\n",
    "            filtered_sid_to_texts_dict.add(key)\n",
    "    return filtered_sid_to_texts_dict\n",
    "\n",
    "def select_random_texts(sid_to_texts_dict, exclude_sid, num_texts=100):\n",
    "    # 過濾掉給定的 SID\n",
    "    filtered_texts = [texts for sid, texts in sid_to_texts_dict.items() if sid != exclude_sid]\n",
    "    \n",
    "    # 將多個列表平坦化為單一列表\n",
    "    all_texts = [text for sublist in filtered_texts for text in sublist]\n",
    "    \n",
    "    # 過濾掉 nan 值\n",
    "    all_texts = [text for text in all_texts if not (isinstance(text, float) and np.isnan(text))]\n",
    "    \n",
    "    # 隨機選擇 100 個文本，若總數少於 100 則選擇所有文本\n",
    "    selected_texts = random.sample(all_texts, min(len(all_texts), num_texts))\n",
    "    \n",
    "    return selected_texts\n",
    "\n",
    "def prompt_generator(pop_df, imap_df, smtp_df, sip_df):\n",
    "    protocols = [\n",
    "    {'name': 'pop_df', 'data': pop_df},\n",
    "    {'name': 'imap_df', 'data': imap_df},\n",
    "    {'name': 'smtp_df', 'data': smtp_df},\n",
    "    {'name': 'sip_df', 'data': sip_df}\n",
    "    ]\n",
    "\n",
    "    with open('prompt.txt', 'w') as file:\n",
    "        pass\n",
    "\n",
    "    with open('prompt.txt', 'a') as file:\n",
    "        for protocol in protocols:\n",
    "            protocol_name = protocol['name']\n",
    "            protocol_data = protocol['data']\n",
    "            \n",
    "            sid_to_unique_texts = map_sid_to_unique_texts(protocol_data)\n",
    "            filtered_sids = filter_sids_by_text_length(sid_to_unique_texts)\n",
    "            \n",
    "            # Sort the filtered_sids to ensure the output is ordered by SID\n",
    "            sorted_filtered_sids = sorted(filtered_sids)\n",
    "            \n",
    "            file.write(f\"Protocol: {protocol_name}\\n\")\n",
    "            \n",
    "            for sid in sorted_filtered_sids:\n",
    "                texts = list(sid_to_unique_texts[sid])\n",
    "                random.shuffle(texts)\n",
    "                selected_texts = texts[:50]\n",
    "                file.write(f\"sid: {sid}, text: {selected_texts}\\n\")\n",
    "                file.write(\"\\n\")\n",
    "                file.write(\"Please find a regular expression to match all packet payloads.\\n\" + \n",
    "                        \"You need to find the similarities in the sentences and generalize the parts where they differ. \\n\" + \n",
    "                            \"The regular expression is in PCRE format, please be aware to evaluate the validity of the expression you generated under PCRE regulations. \\n\" + \n",
    "                            \"There will be examples to help you find the patterns. \\n\"  +\n",
    "                            \"[‘DELE 3\\\\r\\\\n’, ‘DELE 128\\\\r\\\\n’, ‘DELE 74\\\\r\\\\n’, ‘DELE 22\\\\r\\\\n’, ‘DELE 70\\\\r\\\\n’] \\n\" +\n",
    "                            \"These examples show the attacker is trying to delete someone’s email by POP protocol. \\n\" +\n",
    "                            \"The index of the desired mail is indicated under the DELE command. \\n\" +\n",
    "                            \"Thus the best regular expression that matches them will be ‘^(DELE)( )(.*)(\\\\r\\\\n)$’ \\n\" + \"\\n\" +\n",
    "                            \"With the given example payloads: \\n\" +\n",
    "                            \"[‘EHLO BtuCBHdSb51.com\\\\r\\\\n’, ‘EHLO 203.187.87.27\\\\r\\\\n’, ‘EHLO slae02Fo9Ep.com\\\\r\\\\n’, ‘EHLO 210.64.37.51\\\\r\\\\n’, ‘EHLO LLb0RwqdbkikFWo.com\\\\r\\\\n’] \\n\" + \n",
    "                            \"These examples show the attacker is trying to make sure the SMTP server is up and running. \" + \n",
    "                            \"The command EHLO works in both lower case and uppercase, after that follows the SMTP server address. \\n\" +\n",
    "                            \"Thus the best regular expression to match them will be ‘^([E|e][H|h][L|l][O|o])(.*)(\\\\r\\\\n)$’ \\n\" + \"\\n\" +\n",
    "                            \"Next, with the given payloads: \\n\")\n",
    "                file.write(f\"{selected_texts}\\n\")         \n",
    "                file.write(\"Please give 3 possible and different regular expressions to match all of the elements. \\n\" +\n",
    "                            \"You can give only 1 expression if the 3 expressions you find are too similar. \\n\" + \n",
    "                            \"Let’s work this out in a step-by-step way to make sure we have the right answer. \\n\" + \n",
    "                            \"To make the expression not too general, make sure the expressions don’t match these negative examples: [‘CAPA\\\\r\\\\n’, ‘CAPA\\\\r\\\\n’, ‘\\\\x15\\\\x03\\\\x01’, ‘GET / HTTP/1.0\\\\r\\\\n\\\\r\\\\n’, ‘r\\\\n\\\\r\\\\n’] \\n\" +\n",
    "                            \"You only need to give me the three regular expressions in code format.\\n\")\n",
    "                file.write(\"\\n\")\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegexEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "import regex\n",
    "from API.FileProcessor import select_random_texts, map_sid_to_unique_texts\n",
    "\n",
    "def getPcreAnsBySid(sid):\n",
    "    with open('sid_table(packet).csv', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            if row['SID'] == str(sid):\n",
    "                # Remove leading and trailing slashes from the pcre value\n",
    "                return row['pcre']\n",
    "    return None\n",
    "\n",
    "def match_patterns(targetText, GeneratedPatternList,isPositive=True):\n",
    "    non_matching_patterns = []  # Step 1: Initialize list for non-matching patterns\n",
    "    # Check each pattern and add non-matching ones to the list\n",
    "    for i, pattern in enumerate(GeneratedPatternList):\n",
    "        # 确保 pattern 是字符串类型\n",
    "        if not isinstance(pattern, str):\n",
    "            raise TypeError(f\"Pattern at index {i} is not a string: {pattern} (type {type(pattern)})\")\n",
    "        # 确保 targetText 是字符串类型\n",
    "        if not isinstance(targetText, str):\n",
    "            raise TypeError(f\"targetText is not a string: {targetText} (type {type(targetText)})\")\n",
    "        if not regex.search(pattern, targetText, regex.DOTALL):\n",
    "            non_matching_patterns.append(f\"Pattern {i+1}: {pattern}\")\n",
    "    ourResult = True if (9-len(non_matching_patterns)) >= 7 else False\n",
    "    #ansMatch = bool(regex.search(ansPattern, targetText))\n",
    "    return ourResult == isPositive\n",
    "\n",
    "def positive_answer_evaluation(threeAnsPattern,sid,df):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    errorList = []\n",
    "    ansPattern = getPcreAnsBySid(str(sid))\n",
    "    print(f\"ansPattern: {ansPattern}\")\n",
    "    sid_to_unique_texts = map_sid_to_unique_texts(df)\n",
    "    texts = sid_to_unique_texts[sid]\n",
    "    for text in texts:\n",
    "        total = total + 1\n",
    "        correct = correct + bool(regex.search(ansPattern, text, regex.DOTALL))\n",
    "        if not match_patterns(text, threeAnsPattern, True):\n",
    "            errorList.append(text)\n",
    "\n",
    "    print(\"positive test\")\n",
    "    print(f\"correct: {correct}, total: {total}\")\n",
    "    print(f\"errorList: {errorList}\")\n",
    "    return correct, total\n",
    "def negative_answer_evaluation(GeneratedPatternList,sid,sid_to_unique_texts_dict):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    errorList = []\n",
    "    ansPattern = getPcreAnsBySid(str(sid))\n",
    "    texts = select_random_texts(sid_to_unique_texts_dict, sid)\n",
    "    for text in texts:\n",
    "        # 确保 ansPattern 是字符串类型\n",
    "        if not isinstance(ansPattern, str):\n",
    "            raise TypeError(f\"ansPattern is not a string: {ansPattern} (type {type(ansPattern)})\")\n",
    "        # 确保 text 是字符串类型\n",
    "        if not isinstance(text, str):\n",
    "            raise TypeError(f\"text is not a string: {text} (type {type(text)})\")\n",
    "        total = total + 1\n",
    "        if(not regex.search(ansPattern, text, regex.DOTALL)):\n",
    "            correct = correct + 1\n",
    "        if  not match_patterns(text, GeneratedPatternList, False):\n",
    "            errorList.append(text)\n",
    "    print(\"negative test\")\n",
    "    print(f\"correct: {correct}, total: {total}\")\n",
    "    for error_text in errorList:\n",
    "        print(error_text)\n",
    "    print(f\"errorList: {errorList}\")\n",
    "    \n",
    "def positive_evaluation(generatedPattern,sid,sid_to_unique_texts_dict):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    errorList = []\n",
    "    ansPattern = getPcreAnsBySid(str(sid))\n",
    "    print(f\"ansPattern: {ansPattern}\")\n",
    "    texts = sid_to_unique_texts_dict[sid]\n",
    "    for text in texts:\n",
    "        total = total + 1\n",
    "        correct = correct + match_patterns(text, generatedPattern, True)\n",
    "        if not match_patterns(text, generatedPattern, True):\n",
    "            errorList.append(text)\n",
    "\n",
    "    print(\"positive test\")\n",
    "    print(f\"correct: {correct}, total: {total}\")\n",
    "    print(f\"errorList: {errorList}\")\n",
    "    return correct, total\n",
    "\n",
    "def negative_evaluation(GeneratedPatternList,sid,sid_to_unique_texts_dict):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    errorList = []\n",
    "    ansPattern = getPcreAnsBySid(str(sid))\n",
    "    texts = select_random_texts(sid_to_unique_texts_dict, sid,500)\n",
    "    for text in texts:\n",
    "        total = total + 1\n",
    "        correct = correct + match_patterns(text, GeneratedPatternList, False)\n",
    "        if  not match_patterns(text, GeneratedPatternList, False):\n",
    "            errorList.append(text)\n",
    "    print(\"negative test\")\n",
    "    print(f\"correct: {correct}, total: {total}\")\n",
    "    for error_text in errorList:\n",
    "        print(error_text)\n",
    "    print(f\"errorList: {errorList}\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGISTER sip:103.224.193.119 SIP/2.0\n",
      "Via: SIP/2.0/TCP 5.135.73.105:63305;branch=z9hG4bKf20d27fe05934c479e326cab21a80e40;rport\n",
      "To: \"1213\"<sip:1213@103.224.193.119>\n",
      "From: \"1213\"<sip:1213@103.224.193.119>;tag=s0mwgfphds\n",
      "CSeq: 1 REGISTER\n",
      "Call-ID: 339287f550c042d496bc7f3d3e10b950\n",
      "Max-Forwards: 70\n",
      "Contact: <sip:1213@5.135.73.105:63305;transport=TCP>\n",
      "User-Agent: UsaAirport\n",
      "Content-Length: 0\n",
      "Expires: 3600\n",
      "Supported: 100rel\n",
      "Allow: INVITE, ACK, CANCEL, OPTIONS, BYE, SUBSCRIBE, NOTIFY, REFER, INFO, MESSAGE\n",
      "\n",
      "\n",
      "REGISTER sip:175.96.49.102 SIP/2.0\n",
      "Via: SIP/2.0/TCP 5.135.73.105:42904;branch=z9hG4bK2ea52ce548904d7583bd5b4025d670ce;rport\n",
      "To: \"1403\"<sip:1403@175.96.49.102>\n",
      "From: \"1403\"<sip:1403@175.96.49.102>;tag=cni84g8og2\n",
      "CSeq: 1 REGISTER\n",
      "Call-ID: c30accffd70240538e9f320f42738390\n",
      "Max-Forwards: 70\n",
      "Contact: <sip:1403@5.135.73.105:42904;transport=TCP>\n",
      "User-Agent: UsaAirport\n",
      "Content-Length: 0\n",
      "Expires: 3600\n",
      "Supported: 100rel\n",
      "Allow: INVITE, ACK, CANCEL, OPTIONS, BYE, SUBSCRIBE, NOTIFY, REFER, INFO, MESSAGE\n",
      "\n",
      "\n",
      "REGISTER sip:61.62.173.82 SIP/2.0\n",
      "Via: SIP/2.0/TCP 5.135.73.105:12573;branch=z9hG4bK4c6f98a1d70f4a598a98d5f3e9c75d78;rport\n",
      "To: \"1260\"<sip:1260@61.62.173.82>\n",
      "From: \"1260\"<sip:1260@61.62.173.82>;tag=rn0btq5vpm\n",
      "CSeq: 2 REGISTER\n",
      "Call-ID: ade9965f51a447c38366909396633bb1\n",
      "Max-Forwards: 70\n",
      "Contact: <sip:1260@5.135.73.105:12573>\n",
      "User-Agent: UsaAirport\n",
      "Content-Length: 0\n",
      "Expires: 0\n",
      "Supported: 100rel\n",
      "Allow: INVITE, ACK, CANCEL, OPTIONS, BYE, SUBSCRIBE, NOTIFY, REFER, INFO, MESSAGE\n",
      "\n",
      "\n",
      "REGISTER sip:61.67.24.127 SIP/2.0\n",
      "Via: SIP/2.0/TCP 5.135.73.105:50290;branch=z9hG4bK328005320a0e4ad3baadafb154cd574c;rport\n",
      "To: \"694\"<sip:694@61.67.24.127>\n",
      "From: \"694\"<sip:694@61.67.24.127>;tag=dm4ojhdlw4\n",
      "CSeq: 2 REGISTER\n",
      "Call-ID: e75efe034e824bac94b648426fca3890\n",
      "Max-Forwards: 70\n",
      "Contact: <sip:694@5.135.73.105:50290>\n",
      "User-Agent: UsaAirport\n",
      "Content-Length: 0\n",
      "Expires: 0\n",
      "Supported: 100rel\n",
      "Allow: INVITE, ACK, CANCEL, OPTIONS, BYE, SUBSCRIBE, NOTIFY, REFER, INFO, MESSAGE\n",
      "\n",
      "\n",
      "REGISTER sip:210.242.147.74 SIP/2.0\n",
      "Via: SIP/2.0/TCP 5.135.73.105:20687;branch=z9hG4bKe25cce62acca405d8cb553311d04a1c8;rport\n",
      "To: \"633\"<sip:633@210.242.147.74>\n",
      "From: \"633\"<sip:633@210.242.147.74>;tag=2mukkwp7fm\n",
      "CSeq: 1 REGISTER\n",
      "Call-ID: 63235840b8954657b517940acbdfc7cc\n",
      "Max-Forwards: 70\n",
      "Contact: <sip:633@5.135.73.105:20687;transport=TCP>\n",
      "User-Agent: UsaAirport\n",
      "Content-Length: 0\n",
      "Expires: 3600\n",
      "Supported: 100rel\n",
      "Allow: INVITE, ACK, CANCEL, OPTIONS, BYE, SUBSCRIBE, NOTIFY, REFER, INFO, MESSAGE\n",
      "\n",
      "\n",
      "REGISTER sip:61.62.66.97 SIP/2.0\n",
      "Via: SIP/2.0/TCP 5.135.73.105:16084;branch=z9hG4bK4c78d91e73a64a6fa5db3749db45fb54;rport\n",
      "To: \"406\"<sip:406@61.62.66.97>\n",
      "From: \"406\"<sip:406@61.62.66.97>;tag=mlj6ijm033\n",
      "CSeq: 1 REGISTER\n",
      "Call-ID: 4482e4cca343425b9677959b36a26336\n",
      "Max-Forwards: 70\n",
      "Contact: <sip:406@5.135.73.105:16084;transport=TCP>\n",
      "User-Agent: UsaAirport\n",
      "Content-Length: 0\n",
      "Expires: 3600\n",
      "Supported: 100rel\n",
      "Allow: INVITE, ACK, CANCEL, OPTIONS, BYE, SUBSCRIBE, NOTIFY, REFER, INFO, MESSAGE\n",
      "\n",
      "\n",
      "REGISTER sip:61.67.24.123 SIP/2.0\n",
      "Via: SIP/2.0/TCP 5.135.73.105:39697;branch=z9hG4bK4970a80df41e4e4a9f0004efbfc3f179;rport\n",
      "To: \"1383\"<sip:1383@61.67.24.123>\n",
      "From: \"1383\"<sip:1383@61.67.24.123>;tag=lrpocrk90l\n",
      "CSeq: 1 REGISTER\n",
      "Call-ID: f0228c0a1bc14487913e7e9dacb43387\n",
      "Max-Forwards: 70\n",
      "Contact: <sip:1383@5.135.73.105:39697;transport=TCP>\n",
      "User-Agent: UsaAirport\n",
      "Content-Length: 0\n",
      "Expires: 3600\n",
      "Supported: 100rel\n",
      "Allow: INVITE, ACK, CANCEL, OPTIONS, BYE, SUBSCRIBE, NOTIFY, REFER, INFO, MESSAGE\n",
      "\n",
      "\n",
      "REGISTER sip:203.187.87.111 SIP/2.0\n",
      "Via: SIP/2.0/TCP 5.135.73.105:42218;branch=z9hG4bKac6118f487804798b614264aef8e6d4f;rport\n",
      "To: \"1352\"<sip:1352@203.187.87.111>\n",
      "From: \"1352\"<sip:1352@203.187.87.111>;tag=duam0tgrs8\n",
      "CSeq: 1 REGISTER\n",
      "Call-ID: 1d7e5031319243a196e7922733960340\n",
      "Max-Forwards: 70\n",
      "Contact: <sip:1352@5.135.73.105:42218;transport=TCP>\n",
      "User-Agent: UsaAirport\n",
      "Content-Length: 0\n",
      "Expires: 3600\n",
      "Supported: 100rel\n",
      "Allow: INVITE, ACK, CANCEL, OPTIONS, BYE, SUBSCRIBE, NOTIFY, REFER, INFO, MESSAGE\n",
      "\n",
      "\n",
      "REGISTER sip:61.62.66.65 SIP/2.0\n",
      "Via: SIP/2.0/TCP 5.135.73.105:51463;branch=z9hG4bKa43768fb94f7422a89f92ab07b075a9b;rport\n",
      "To: \"567\"<sip:567@61.62.66.65>\n",
      "From: \"567\"<sip:567@61.62.66.65>;tag=c2ahus8gs0\n",
      "CSeq: 2 REGISTER\n",
      "Call-ID: 2b14196dc91b491793016e381baa7cfa\n",
      "Max-Forwards: 70\n",
      "Contact: <sip:567@5.135.73.105:51463>\n",
      "User-Agent: UsaAirport\n",
      "Content-Length: 0\n",
      "Expires: 0\n",
      "Supported: 100rel\n",
      "Allow: INVITE, ACK, CANCEL, OPTIONS, BYE, SUBSCRIBE, NOTIFY, REFER, INFO, MESSAGE\n",
      "\n",
      "\n",
      "REGISTER sip:61.67.24.124 SIP/2.0\n",
      "Via: SIP/2.0/TCP 5.135.73.105:26654;branch=z9hG4bKa378bc7426914adea55f1aa47f87da17;rport\n",
      "To: \"1367\"<sip:1367@61.67.24.124>\n",
      "From: \"1367\"<sip:1367@61.67.24.124>;tag=edqjqqbcoj\n",
      "CSeq: 1 REGISTER\n",
      "Call-ID: 40035f414bcd469eb5a06c851c49b055\n",
      "Max-Forwards: 70\n",
      "Contact: <sip:1367@5.135.73.105:26654;transport=TCP>\n",
      "User-Agent: UsaAirport\n",
      "Content-Length: 0\n",
      "Expires: 3600\n",
      "Supported: 100rel\n",
      "Allow: INVITE, ACK, CANCEL, OPTIONS, BYE, SUBSCRIBE, NOTIFY, REFER, INFO, MESSAGE\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    texts = select_random_texts(sid_to_unique_texts_dict, \"1161912\",10)\n",
    "    for text in texts:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df = readPkl(\"pop_report_with_tknscore_new.pkl\")\n",
    "imap_df = readPkl(\"imap_report_with_tknscore_new.pkl\")\n",
    "smtp_df = readPkl(\"smtp_report_with_tknscore_new.pkl\")\n",
    "sip_df = readPkl(\"sip_report_with_tknscore_new.pkl\")\n",
    "label_df = readCsv(\"sid_table(packet).csv\")\n",
    "\n",
    "dfs = [pop_df, imap_df, smtp_df, sip_df]\n",
    "sid_to_unique_texts_dict = merge_dataframes_to_dict(dfs)\n",
    "filted_sid = filter_sids_by_text_length(sid_to_unique_texts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(bool(regex.search(\"^([E|e][H|h][L|l][O|o])( [a-zA-Z0-9.-]+)?(\\\\r\\\\n)$\", \"EHLO 61.67.24.58\\r\\n\", regex.DOTALL)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ansPattern: /^([E|e][H|h][L|l][O|o])(.*)(\\r\\n)$/\n",
      "positive test\n",
      "correct: 2641, total: 2660\n",
      "errorList: ['ehlo WIN-2887F9VDJAL\\r\\n', 'EHLO [127.0.0.1]\\r\\n', 'Ehlo [204.93.160.206]\\r\\n', 'Ehlo [172.245.24.107]\\r\\n', 'ehlo WIN-9P8L97OHU8U\\r\\n', 'ehlo hello\\r\\n', 'ehlo WIN-ET94B53A27P\\r\\n', 'ehlo WIN-CLJ1B0GQ6JP\\r\\n', 'ehlo AB-201803070904\\r\\n', 'EHLO 103.224.192.5\\r\\nQUIT\\r\\n', 'EHLO []\\r\\n', 'EHLO User\\r\\nQUIT\\r\\n', 'ehlo [193.56.28.126]\\r\\n', 'ehlo WIN-25FFVSIPLS1\\r\\n', 'Ehlo [79.137.121.218]\\r\\n', 'ehlo RDS01\\r\\n', 'ehlo win2012r2RDP\\r\\n', 'Ehlo [192.168.1.11]\\r\\n', 'ehlo Accounting\\r\\n']\n",
      "negative test\n",
      "correct: 500, total: 500\n",
      "errorList: []\n"
     ]
    }
   ],
   "source": [
    "GeneratedPatternList = [\n",
    "\"^([E|e][H|h][L|l][O|o])( [a-zA-Z0-9.-]+)?(\\\\r\\\\n)$\", \n",
    "\"^EHLO( [a-zA-Z0-9.-]+)?(\\\\r\\\\n)$\", \n",
    "\"^([Ee][Hh][Ll][Oo])( [a-zA-Z0-9.-]+)?(\\\\r\\\\n)$\", \n",
    "\"^([E|e][H|h][L|l][O|o] [a-zA-Z0-9.-]+(\\\\.[a-zA-Z]{2,})?\\\\r\\\\n)$\", \n",
    "\"^([E|e][H|h][L|l][O|o] [a-zA-Z0-9.-]+(\\\\.[a-zA-Z0-9.-]+)+\\\\r\\\\n|[E|e][H|h][L|l][O|o]\\\\r\\\\n)$\", \n",
    "\"^([E|e][H|h][L|l][O|o]( [a-zA-Z0-9.-]+(\\\\.[a-zA-Z0-9.-]+)+)?\\\\r\\\\n)$\", \n",
    "\"^(EHLO|ehlo)( [^\\\\r\\\\n]+)?(\\\\r\\\\n)$\", \n",
    "\"^([E|e][H|h][L|l][O|o])( [a-zA-Z0-9.-]+)?(\\\\r\\\\n)$\", \n",
    "\"^([Ee][Hh][Ll][Oo])( [a-zA-Z0-9.-]+)?(\\\\r\\\\n)$$\"\n",
    "]\n",
    "\n",
    "SID = '1454621'\n",
    "positive_evaluation(GeneratedPatternList, SID, sid_to_unique_texts_dict)\n",
    "negative_evaluation(GeneratedPatternList, SID, sid_to_unique_texts_dict)\n",
    "#後處理 \"前面加\\\n",
    "#\\前面加\\\n",
    "#把首尾的/去掉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#獲取各個SID所對應到的text\n",
    "def map_sid_to_unique_texts(df):\n",
    "    sid_to_texts = {}\n",
    "    for _, row in df.iterrows():\n",
    "        sid = row['sid']\n",
    "        text = row['text']\n",
    "        if pd.notnull(text):  # Ensure text is not NaN\n",
    "            if sid in sid_to_texts:\n",
    "                sid_to_texts[sid].add(text)\n",
    "            else:\n",
    "                sid_to_texts[sid] = {text}\n",
    "    return sid_to_texts\n",
    "sid_to_unique_texts = map_sid_to_unique_texts(pop_df)\n",
    "#print(sid_to_unique_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#過濾掉text長度小於5的sid\n",
    "def filter_sids_by_text_length(sit_to_text_dict):\n",
    "    filtered_sids = set()\n",
    "    for key, value in sit_to_text_dict.items():\n",
    "        if len(value) > 5:  # Convert to string to avoid errors with non-string types\n",
    "            filtered_sids.add(key)\n",
    "    return filtered_sids\n",
    "\n",
    "# Assuming pop_df is your DataFrame\n",
    "filtered_sids = filter_sids_by_text_length(sid_to_unique_texts)\n",
    "#print(filtered_sids)\n",
    "#print(len(filtered_sids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcre_by_sid(sid):\n",
    "    with open('sid_table(packet).csv', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            if row['SID'] == str(sid):\n",
    "                # Remove leading and trailing slashes from the pcre value\n",
    "                print (row['pcre'])\n",
    "                return row['pcre'].strip('/')\n",
    "    return None\n",
    "\n",
    "# Iterate Throush Positive payload text to see if the ans regex is correct    \n",
    "def is_ans_correct(sid):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    errorList = []\n",
    "    ansPattern = get_pcre_by_sid(str(sid))\n",
    "    print(f\"ansPattern: {ansPattern}\")\n",
    "    sid_to_unique_texts = map_sid_to_unique_texts(pop_df)\n",
    "    texts = sid_to_unique_texts[sid]\n",
    "    for text in texts:\n",
    "        total = total + 1\n",
    "        correct = correct + bool(regex.search(ansPattern, text,regex.DOTALL))\n",
    "        if not bool(regex.search(r'/^(GET|HEAD|POST|OPTIONS)( )(\\/|\\/version|\\/api.*|\\/jsproxy)( )(HTTP\\/1\\.(?:0|1))(\\r\\n)(.*)$/', text,regex.DOTALL)):\n",
    "            errorList.append(text)\n",
    "\n",
    "    print(\"answer test\")\n",
    "    print(f\"correct: {correct}, total: {total}\")\n",
    "    print(len(errorList))\n",
    "    for error in errorList:\n",
    "        print(f\"error: {error}\")\n",
    "    return correct, total\n",
    "is_ans_correct('1783777')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPT API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "CHAT_GPT_API_KEY = os.getenv('C_API_KEY')\n",
    "client = OpenAI(\n",
    "    api_key=CHAT_GPT_API_KEY\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "system_prompt = \"You are a cat. Your name is Neko.\"\n",
    "user_prompt = \"What is your name?\"\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "model=genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  system_instruction=system_prompt)\n",
    "\n",
    "response = model.generate_content(user_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Generated Regex\n",
    "Randonly take 20 positive and 20 negateve data as input to generated regex and answer regex, comparing there result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#隨機選擇除了給定的SID以外的100個text\n",
    "def select_random_texts(sid_to_unique_texts, given_sid, num_texts=100):\n",
    "    # Filter out the given SID\n",
    "    filtered_texts = [texts for sid, texts in sid_to_unique_texts.items() if sid != given_sid]\n",
    "    \n",
    "    # Flatten the list of lists to a single list of texts\n",
    "    all_texts = [text for sublist in filtered_texts for text in sublist]\n",
    "    \n",
    "    # Randomly select 100 texts, or all texts if there are fewer than 100\n",
    "    selected_texts = random.sample(all_texts, min(len(all_texts), num_texts))\n",
    "    \n",
    "    return selected_texts\n",
    "\n",
    "def get_pcre_by_sid(sid):\n",
    "    with open('sid_table(packet).csv', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            if row['SID'] == str(sid):\n",
    "                # Remove leading and trailing slashes from the pcre value\n",
    "                return row['pcre']\n",
    "    return None\n",
    "\n",
    "def match_patterns(targetText, GeneratedPatternList,isPositive=True):\n",
    "    non_matching_patterns = []  # Step 1: Initialize list for non-matching patterns\n",
    "    # Check each pattern and add non-matching ones to the list\n",
    "    for i, pattern in enumerate(GeneratedPatternList):\n",
    "        if not regex.search(pattern, targetText, regex.DOTALL):\n",
    "            non_matching_patterns.append(f\"Pattern {i+1}: {pattern}\")\n",
    "    ourResult = True if (9-len(non_matching_patterns)) >= 7 else False\n",
    "    with open('evaluation_result.txt', 'w') as file:\n",
    "        for pattern in non_matching_patterns:\n",
    "            file.write(pattern)\n",
    "    #ansMatch = bool(regex.search(ansPattern, targetText))\n",
    "    return ourResult == isPositive\n",
    "\n",
    "def positive_answer_evaluation(threeAnsPattern,sid):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    errorList = []\n",
    "    ansPattern = get_pcre_by_sid(str(sid))\n",
    "    print(f\"ansPattern: {ansPattern}\")\n",
    "    sid_to_unique_texts = map_sid_to_unique_texts(pop_df)\n",
    "    texts = sid_to_unique_texts[sid]\n",
    "    for text in texts:\n",
    "        total = total + 1\n",
    "        correct = correct + bool(regex.search(ansPattern, text, regex.DOTALL))\n",
    "        if not match_patterns(text, threeAnsPattern, True):\n",
    "            errorList.append(text)\n",
    "\n",
    "    print(\"positive test\")\n",
    "    print(f\"correct: {correct}, total: {total}\")\n",
    "    print(f\"errorList: {errorList}\")\n",
    "    return correct, total\n",
    "def negative_answer_evaluation(GeneratedPatternList,sid):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    errorList = []\n",
    "    ansPattern = get_pcre_by_sid(str(sid))\n",
    "    texts = select_random_texts(sid_to_unique_texts, sid)\n",
    "    for text in texts:\n",
    "        total = total + 1\n",
    "        if(not regex.search(ansPattern, text, regex.DOTALL)):\n",
    "            correct = correct + 1\n",
    "        if  not match_patterns(text, GeneratedPatternList, False):\n",
    "            errorList.append(text)\n",
    "    print(\"negative test\")\n",
    "    print(f\"correct: {correct}, total: {total}\")\n",
    "    for error_text in errorList:\n",
    "        print(error_text)\n",
    "    print(f\"errorList: {errorList}\")\n",
    "    \n",
    "def positive_evaluation(threeAnsPattern,sid):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    errorList = []\n",
    "    ansPattern = get_pcre_by_sid(str(sid))\n",
    "    print(f\"ansPattern: {ansPattern}\")\n",
    "    sid_to_unique_texts = map_sid_to_unique_texts(pop_df)\n",
    "    texts = sid_to_unique_texts[sid]\n",
    "    for text in texts:\n",
    "        total = total + 1\n",
    "        correct = correct + match_patterns(text, threeAnsPattern, True)\n",
    "        if not match_patterns(text, threeAnsPattern, True):\n",
    "            errorList.append(text)\n",
    "\n",
    "    print(\"positive test\")\n",
    "    print(f\"correct: {correct}, total: {total}\")\n",
    "    print(f\"errorList: {errorList}\")\n",
    "    return correct, total\n",
    "\n",
    "def negative_evaluation(GeneratedPatternList,sid):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    errorList = []\n",
    "    ansPattern = get_pcre_by_sid(str(sid))\n",
    "    texts = select_random_texts(sid_to_unique_texts, sid)\n",
    "    for text in texts:\n",
    "        total = total + 1\n",
    "        correct = correct + match_patterns(text, GeneratedPatternList, False)\n",
    "        if  not match_patterns(text, GeneratedPatternList, False):\n",
    "            errorList.append(text)\n",
    "    print(\"negative test\")\n",
    "    print(f\"correct: {correct}, total: {total}\")\n",
    "    for error_text in errorList:\n",
    "        print(error_text)\n",
    "    print(f\"errorList: {errorList}\")\n",
    "    \n",
    "regex1 = r\"/^([E|e][H|h][L|l][O|o])( [a-zA-Z0-9.-]+)?(\\r\\n)$/\"\n",
    "regex2 = r\"/^EHLO( [a-zA-Z0-9.-]+)?(\\r\\n)$/\"\n",
    "regex3 = r\"/^([Ee][Hh][Ll][Oo])( [a-zA-Z0-9.-]+)?(\\r\\n)$/\"\n",
    "regex4 = r\"^([E|e][H|h][L|l][O|o] [a-zA-Z0-9.-]+(\\.[a-zA-Z]{2,})?\\r\\n)$\"\n",
    "regex5 = r\"^([E|e][H|h][L|l][O|o] [a-zA-Z0-9.-]+(\\.[a-zA-Z0-9.-]+)+\\r\\n|[E|e][H|h][L|l][O|o]\\r\\n)$\"\n",
    "regex6 = r\"^([E|e][H|h][L|l][O|o]( [a-zA-Z0-9.-]+(\\.[a-zA-Z0-9.-]+)+)?\\r\\n)$\"\n",
    "regex7 = r\"^(EHLO|ehlo)( [^\\r\\n]+)?(\\r\\n)$\"\n",
    "regex8 = r\"^([E|e][H|h][L|l][O|o])( [a-zA-Z0-9.-]+)?(\\r\\n)$\"\n",
    "regex9 = r\"^([Ee][Hh][Ll][Oo])( [a-zA-Z0-9.-]+)?(\\r\\n)$\"\n",
    "GeneratedPatternList = [\n",
    "    regex1, regex2, regex3, regex4, regex5, regex6, regex7, regex8, regex9\n",
    "]\n",
    "\n",
    "sid = '1454621'\n",
    "positive_evaluation(GeneratedPatternList, sid)\n",
    "negative_evaluation(GeneratedPatternList, sid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_csv_columns():\n",
    "    with open('sid_table(packet).csv', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        # Print all column names\n",
    "        print(reader.fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print filtered_sids and corresponding text\n",
    "for sid in filtered_sids:\n",
    "    print(f\"sid: {sid}, text: {sid_to_unique_texts[sid]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols = [\n",
    "    {'name': 'pop_df', 'data': pop_df},\n",
    "    {'name': 'imap_df', 'data': imap_df},\n",
    "    {'name': 'smtp_df', 'data': smtp_df},\n",
    "    {'name': 'sip_df', 'data': sip_df}\n",
    "]\n",
    "\n",
    "with open('prompt.txt', 'w') as file:\n",
    "    pass\n",
    "\n",
    "with open('prompt.txt', 'a') as file:\n",
    "    for protocol in protocols:\n",
    "        protocol_name = protocol['name']\n",
    "        protocol_data = protocol['data']\n",
    "        \n",
    "        sid_to_unique_texts = map_sid_to_unique_texts(protocol_data)\n",
    "        filtered_sids = filter_sids_by_text_length(sid_to_unique_texts)\n",
    "        \n",
    "        # Sort the filtered_sids to ensure the output is ordered by SID\n",
    "        sorted_filtered_sids = sorted(filtered_sids)\n",
    "        \n",
    "        file.write(f\"Protocol: {protocol_name}\\n\")\n",
    "        \n",
    "        for sid in sorted_filtered_sids:\n",
    "            texts = list(sid_to_unique_texts[sid])\n",
    "            random.shuffle(texts)\n",
    "            selected_texts = texts[:50]\n",
    "            file.write(f\"sid: {sid}, text: {selected_texts}\\n\")\n",
    "            file.write(\"\\n\")\n",
    "            file.write(\"Please find a regular expression to match all packet payloads.\\n\" + \n",
    "                       \"You need to find the similarities in the sentences and generalize the parts where they differ. \\n\" + \n",
    "                        \"The regular expression is in PCRE format, please be aware to evaluate the validity of the expression you generated under PCRE regulations. \\n\" + \n",
    "                        \"There will be examples to help you find the patterns. \\n\"  +\n",
    "                        \"[‘DELE 3\\\\r\\\\n’, ‘DELE 128\\\\r\\\\n’, ‘DELE 74\\\\r\\\\n’, ‘DELE 22\\\\r\\\\n’, ‘DELE 70\\\\r\\\\n’] \\n\" +\n",
    "                        \"These examples show the attacker is trying to delete someone’s email by POP protocol. \\n\" +\n",
    "                        \"The index of the desired mail is indicated under the DELE command. \\n\" +\n",
    "                        \"Thus the best regular expression that matches them will be ‘^(DELE)( )(.*)(\\\\r\\\\n)$’ \\n\" + \"\\n\" +\n",
    "                        \"With the given example payloads: \\n\" +\n",
    "                        \"[‘EHLO BtuCBHdSb51.com\\\\r\\\\n’, ‘EHLO 203.187.87.27\\\\r\\\\n’, ‘EHLO slae02Fo9Ep.com\\\\r\\\\n’, ‘EHLO 210.64.37.51\\\\r\\\\n’, ‘EHLO LLb0RwqdbkikFWo.com\\\\r\\\\n’] \\n\" + \n",
    "                        \"These examples show the attacker is trying to make sure the SMTP server is up and running. \" + \n",
    "                        \"The command EHLO works in both lower case and uppercase, after that follows the SMTP server address. \\n\" +\n",
    "                        \"Thus the best regular expression to match them will be ‘^([E|e][H|h][L|l][O|o])(.*)(\\\\r\\\\n)$’ \\n\" + \"\\n\" +\n",
    "                        \"Next, with the given payloads: \\n\")\n",
    "            file.write(f\"{selected_texts}\\n\")         \n",
    "            file.write(\"Please give 3 possible and different regular expressions to match all of the elements. \\n\" +\n",
    "                        \"You can give only 1 expression if the 3 expressions you find are too similar. \\n\" + \n",
    "                        \"Let’s work this out in a step-by-step way to make sure we have the right answer. \\n\" + \n",
    "                        \"To make the expression not too general, make sure the expressions don’t match these negative examples: [‘CAPA\\\\r\\\\n’, ‘CAPA\\\\r\\\\n’, ‘\\\\x15\\\\x03\\\\x01’, ‘GET / HTTP/1.0\\\\r\\\\n\\\\r\\\\n’, ‘r\\\\n\\\\r\\\\n’] \\n\" +\n",
    "                        \"You only need to give me the three regular expressions in code format.\\n\")\n",
    "            file.write(\"\\n\")\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_texts.txt', 'a') as file:\n",
    "    for protocol in protocols:\n",
    "        protocol_name = protocol['name']\n",
    "        protocol_data = protocol['data']\n",
    "        \n",
    "        sid_to_unique_texts = map_sid_to_unique_texts(protocol_data)\n",
    "        filtered_sids = filter_sids_by_text_length(sid_to_unique_texts)\n",
    "        \n",
    "        file.write(f\"Protocol: {protocol_name}\\n\")\n",
    "        \n",
    "        for sid in filtered_sids:\n",
    "            file.write(f\"sid: {sid}, text: {sid_to_unique_texts[sid]}\\n\")\n",
    "\n",
    "        file.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
