{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the pickle file and find the top five occurance rate payloads in the file\n",
    "Return the payloads as 'text'讀取出text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pop_report_with_tknscore_new.pkl\", \"rb\") as f:\n",
    "    pop_df = pickle.load(f)\n",
    "\n",
    "with open(\"imap_report_with_tknscore_new.pkl\", \"rb\") as f:\n",
    "    imap_df = pickle.load(f)\n",
    "\n",
    "with open(\"smtp_report_with_tknscore_new.pkl\", \"rb\") as f:\n",
    "    smtp_df = pickle.load(f)\n",
    "\n",
    "with open(\"sip_report_with_tknscore_new.pkl\", \"rb\") as f:\n",
    "    sip_df = pickle.load(f)\n",
    "\n",
    "# label_df = pd.read_csv(\"sid_table(packet).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 流程\n",
    "### 獲取目標資料\n",
    "- 獲取特定資料集的所有SID(unique)\n",
    "- 獲取各個SID所對應到的text\n",
    "- 過濾出sizt(text)>5的SID\n",
    "- 對這些SID用LLM自動生成regex(生成Regex流程)\n",
    "### 生成Regex\n",
    "- 對每一個SID給LLM幾個regex例子\n",
    "- 要求LLM生成三個不一樣但是可以過濾text的regex\n",
    "### 測試Regex\n",
    "- 拿答案給的regex和我們生成的regex測試能否的到相同結果(2/3過算對)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#獲取特定資料集的所有SID\n",
    "def get_unique_sids_list(df):\n",
    "    unique_sids = df[df['text'].notnull()]['sid'].unique()\n",
    "    return unique_sids\n",
    "sidList = get_unique_sids_list(pop_df)\n",
    "print(sidList)\n",
    "print(len(sidList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#獲取各個SID所對應到的text\n",
    "def map_sid_to_unique_texts(df):\n",
    "    sid_to_texts = {}\n",
    "    for _, row in df.iterrows():\n",
    "        sid = row['sid']\n",
    "        text = row['text']\n",
    "        if pd.notnull(text):  # Ensure text is not NaN\n",
    "            if sid in sid_to_texts:\n",
    "                sid_to_texts[sid].add(text)\n",
    "            else:\n",
    "                sid_to_texts[sid] = {text}\n",
    "    return sid_to_texts\n",
    "sid_to_unique_texts = map_sid_to_unique_texts(pop_df)\n",
    "print(sid_to_unique_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#過濾掉text長度小於5的sid\n",
    "def filter_sids_by_text_length(sit_to_text_dict):\n",
    "    filtered_sids = set()\n",
    "    for key, value in sit_to_text_dict.items():\n",
    "        if len(value) > 5:  # Convert to string to avoid errors with non-string types\n",
    "            filtered_sids.add(key)\n",
    "    return filtered_sids\n",
    "\n",
    "# Assuming pop_df is your DataFrame\n",
    "filtered_sids = filter_sids_by_text_length(sid_to_unique_texts)\n",
    "print(filtered_sids)\n",
    "print(len(filtered_sids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPT API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "CHAT_GPT_API_KEY = os.getenv('C_API_KEY')\n",
    "client = OpenAI(\n",
    "    api_key=CHAT_GPT_API_KEY\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "system_prompt = \"You are a cat. Your name is Neko.\"\n",
    "user_prompt = \"What is your name?\"\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "model=genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  system_instruction=system_prompt)\n",
    "\n",
    "response = model.generate_content(user_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Generated Regex\n",
    "Randonly take 20 positive and 20 negateve data as input to generated regex and answer regex, comparing there result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive test\n",
      "correct: 0, total: 45\n",
      "errorList: ['USER world@gmail.com', 'USER spam.passed@camihun.com\\r\\n', 'USER spam.blocked@yutouzhou.com\\r\\n', 'USER informix\\r\\n', 'USER www\\r\\n', 'USER oracle\\r\\n', 'USER spam.blocked@dihuigui.com\\r\\n', 'USER test\\r\\n', 'USER account\\r\\n', 'USER data\\r\\n', 'USER spam.passed@oamishuang.com\\r\\n', 'USER sybase\\r\\n', 'USER spam.passed@yutouzhou.com\\r\\n', 'USER spam.blocked@tougurou.com\\r\\n', 'USER server\\r\\n', 'USER spam.passed@dihuigui.com\\r\\n', 'USER spam.passed@caitaogui.com\\r\\n', 'USER spam.blocked@zhuxietang.com\\r\\n', 'USER spam.blocked@hanghanji.com\\r\\n', 'USER administrator\\r\\n', 'USER spam.passed@tougurou.com\\r\\n', 'USER backup\\r\\n', 'USER webmaster\\r\\n', 'USER spam.blocked@dikamishuang.com\\r\\n', 'USER spam.blocked@caodaofu.com\\r\\n', 'USER spam.passed@dikamishuang.com\\r\\n', 'USER spam.passed@guinengo.com\\r\\n', 'USER root\\r\\n', 'USER spam.blocked@camihun.com\\r\\n', 'USER spam.blocked@caitaogui.com\\r\\n', 'USER access\\r\\n', 'USER spam.blocked@guinengo.com\\r\\n', 'USER spam.blocked@oamishuang.com\\r\\n', 'USER spam.blocked@tangqingcai.com\\r\\n', 'USER spam.passed@caodaofu.com\\r\\n', 'USER web\\r\\n', 'USER spam.passed@zhuxietang.com\\r\\n', 'USER spam.passed@hanghanji.com\\r\\n', 'USER admin\\r\\n', 'USER anonymous\\r\\n', 'USER pwrchute\\r\\n', 'USER user\\r\\n', 'USER oracle8\\r\\n', 'USER lizdy\\r\\n', 'USER spam.passed@tangqingcai.com\\r\\n']\n",
      "^(USER)( )(.*)$\n",
      "negative test\n",
      "correct: 100, total: 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import csv\n",
    "import random\n",
    "\n",
    "#隨機選擇除了給定的SID以外的100個text\n",
    "def select_random_texts(sid_to_unique_texts, given_sid, num_texts=100):\n",
    "    # Filter out the given SID\n",
    "    filtered_texts = [texts for sid, texts in sid_to_unique_texts.items() if sid != given_sid]\n",
    "    \n",
    "    # Flatten the list of lists to a single list of texts\n",
    "    all_texts = [text for sublist in filtered_texts for text in sublist]\n",
    "    \n",
    "    # Randomly select 100 texts, or all texts if there are fewer than 100\n",
    "    selected_texts = random.sample(all_texts, min(len(all_texts), num_texts))\n",
    "    \n",
    "    return selected_texts\n",
    "\n",
    "def get_pcre_by_sid(sid):\n",
    "    with open('sid_table(packet).csv', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            if row['SID'] == str(sid):\n",
    "                # Remove leading and trailing slashes from the pcre value\n",
    "                return row['pcre'].strip('/')\n",
    "    return None\n",
    "\n",
    "def match_patterns(targetText, threeAnsPattern,ansPattern):\n",
    "    match1 = bool(re.search(threeAnsPattern[0], targetText))\n",
    "    match2 = bool(re.search(threeAnsPattern[1], targetText))\n",
    "    match3 = bool(re.search(threeAnsPattern[2], targetText))\n",
    "    ourResult = sum([match1, match2, match3]) >= 2\n",
    "    match4 = bool(re.search(ansPattern, targetText))\n",
    "    return ourResult == match4\n",
    "def positive_evaluation(threeAnsPattern,sid):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    errorList = []\n",
    "    ansPattern = get_pcre_by_sid(str(sid))\n",
    "    sid_to_unique_texts = map_sid_to_unique_texts(pop_df)\n",
    "    texts = sid_to_unique_texts[sid]\n",
    "    for text in texts:\n",
    "        total = total + 1\n",
    "        correct = correct + match_patterns(text, threeAnsPattern, ansPattern)\n",
    "        if not match_patterns(text, threeAnsPattern, ansPattern):\n",
    "            errorList.append(text)\n",
    "\n",
    "    print(\"positive test\")\n",
    "    print(f\"correct: {correct}, total: {total}\")\n",
    "    print(f\"errorList: {errorList}\")\n",
    "    return correct, total\n",
    "\n",
    "def negative_evaluation(threeAnsPattern,sid):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    errorList = []\n",
    "    ansPattern = get_pcre_by_sid(str(sid))\n",
    "    texts = select_random_texts(sid_to_unique_texts, sid)\n",
    "    print(ansPattern)\n",
    "    for text in texts:\n",
    "        total = total + 1\n",
    "        correct = correct + match_patterns(text, threeAnsPattern, ansPattern)\n",
    "        if  not match_patterns(text, threeAnsPattern, ansPattern):\n",
    "            errorList.append(text)\n",
    "    print(\"negative test\")\n",
    "    print(f\"correct: {correct}, total: {total}\")\n",
    "    for error_text in errorList:\n",
    "        print(error_text)\n",
    "    #print(f\"errorList: {errorList}\")\n",
    "threeAnsPattern = [\n",
    "    r\"^(USER) ([a-zA-Z0-9._%-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}|anonymous)(\\\\r\\\\n)$\",\n",
    "    r\"^(USER) (.+@.+\\\\..+|anonymous)(\\\\r\\\\n)$\",\n",
    "    r\"^(USER) ([a-zA-Z0-9._%-]+@[a-zA-Z0-9.-]+|anonymous)(\\\\r\\\\n)$\"\n",
    "]\n",
    "\n",
    "sid = '1648627'\n",
    "positive_evaluation(threeAnsPattern, sid)\n",
    "negative_evaluation(threeAnsPattern, sid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_csv_columns():\n",
    "    with open('sid_table(packet).csv', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        # Print all column names\n",
    "        print(reader.fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print filtered_sids and corresponding text\n",
    "for sid in filtered_sids:\n",
    "    print(f\"sid: {sid}, text: {sid_to_unique_texts[sid]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "protocols = [\n",
    "    {'name': 'pop_df', 'data': pop_df},\n",
    "    {'name': 'imap_df', 'data': imap_df},\n",
    "    {'name': 'smtp_df', 'data': smtp_df},\n",
    "    {'name': 'sip_df', 'data': sip_df}\n",
    "]\n",
    "\n",
    "with open('target.txt', 'w') as file:\n",
    "    pass\n",
    "\n",
    "with open('target.txt', 'a') as file:\n",
    "    for protocol in protocols:\n",
    "        protocol_name = protocol['name']\n",
    "        protocol_data = protocol['data']\n",
    "        \n",
    "        sid_to_unique_texts = map_sid_to_unique_texts(protocol_data)\n",
    "        filtered_sids = filter_sids_by_text_length(sid_to_unique_texts)\n",
    "        \n",
    "        file.write(f\"Protocol: {protocol_name}\\n\")\n",
    "        \n",
    "        for sid in filtered_sids:\n",
    "            texts = list(sid_to_unique_texts[sid])\n",
    "            random.shuffle(texts)\n",
    "            selected_texts = texts[:50]\n",
    "            file.write(f\"sid: {sid}, text: {selected_texts}\\n \\n\")\n",
    "            file.write(\"Please find a regular expression to match all packet payloads.\\n\" + \n",
    "                       \"You need to find the similarities in the sentences and generalize the parts where they differ. \\n\" + \n",
    "                        \"The regular expression is in PCRE fromat, please be aware to evaluate the validity of the expression you generated under PCRE regulations. \\n\" + \n",
    "                        \"There will be examples to help you find the patterns. \\n\"  +\n",
    "                        \"with the given example payloads: \\n\" +\n",
    "                        \"[‘DELE 3\\\\r\\\\n’, ‘DELE 128\\\\r\\\\n’, ‘DELE 74\\\\r\\\\n’, ‘DELE 22\\\\r\\\\n’, ‘DELE 70\\\\r\\\\n’] \\n\" +\n",
    "                        \"These examples show the attacker is trying to delete someone’s email by POP protocol. \\n\" +\n",
    "                        \"The index of the desired mail is indicated under the DELE command. \\n\" +\n",
    "                        \"Thus the best regular expression that matches them will be ‘^(DELE)( )(.*)(\\\\r\\\\n)$’ \\n\" + \"\\n\" +\n",
    "                        \"With the given example payloads: \\n\" +\n",
    "                        \"[‘EHLO BtuCBHdSb51.com\\\\r\\\\n’, ‘EHLO 203.187.87.27\\\\r\\\\n’, ‘EHLO slae02Fo9Ep.com\\\\r\\\\n’, ‘EHLO 210.64.37.51\\\\r\\\\n’, ‘EHLO LLb0RwqdbkikFWo.com\\\\r\\\\n’] \\n\" + \n",
    "                        \"These examples show the attacker is trying to make sure the SMTP server is up and running. \" + \n",
    "                        \"The command EHLO works in both lower case and uppercase, after that follows the SMTP server address. \\n\" +\n",
    "                        \"Thus the best regular expression to match them will be ‘^([E|e][H|h][L|l][O|o])(.*)(\\\\r\\\\\\n)$’ \\n\" + \"\\n\" +\n",
    "                        \"Next, with the given payloads: \\n\")\n",
    "            file.write(f\"{selected_texts}\\n\")         \n",
    "            file.write(\"Please give 3 possible and different regular expressions to match all of the elements. \\n\" +\n",
    "                        \"You can give only 1 expression if the 3 expressions you find are too similar. \\n\" + \n",
    "                        \"Let’s work this out in a step-by-step way to make sure we have the right answer. \\n\" + \n",
    "                        \"To make the expression not too general, make sure the expressions don’t match these negative examples: [‘CAPA\\\\r\\\\n’, ‘CAPA\\\\r\\\\n’, ‘\\\\x15\\\\x03\\\\x01’, ‘GET / HTTP/1.0\\\\r\\\\n\\\\r\\\\n’, ‘r\\\\n\\\\r\\\\n’] \\n\")\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_texts.txt', 'a') as file:\n",
    "    for protocol in protocols:\n",
    "        protocol_name = protocol['name']\n",
    "        protocol_data = protocol['data']\n",
    "        \n",
    "        sid_to_unique_texts = map_sid_to_unique_texts(protocol_data)\n",
    "        filtered_sids = filter_sids_by_text_length(sid_to_unique_texts)\n",
    "        \n",
    "        file.write(f\"Protocol: {protocol_name}\\n\")\n",
    "        \n",
    "        for sid in filtered_sids:\n",
    "            file.write(f\"sid: {sid}, text: {sid_to_unique_texts[sid]}\\n\")\n",
    "\n",
    "        file.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
